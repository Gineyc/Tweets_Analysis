{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected  <tweepy.api.API object at 0x00000233C4F42E88>\n"
     ]
    }
   ],
   "source": [
    "# Import the must library\n",
    "import tweepy \n",
    "import csv\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "#input the auth key to connect tweepy api, print result if connected sucessfully, \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CONSUMER_KEY = *'\n",
    "CONSUMER_SECRET = '*'\n",
    "OAUTH_TOKEN = '*'\n",
    "OAUTH_TOKEN_SECRET = '*'\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "    auth.set_access_token(OAUTH_TOKEN,OAUTH_TOKEN_SECRET)\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "    print(\"connected \",api)\n",
    "except:\n",
    "    print(\"Error: Authentication Failed\") \n",
    "    \n",
    "def tweets_crawling(hashtag,tweet_mode,lang,result_type,pagecount,items):\n",
    "    df = pd.DataFrame()\n",
    "    msgs = []\n",
    "    msg =[]\n",
    "    for tweet in tweepy.Cursor(api.search,q=hashtag,tweet_mode=tweet_mode,lang=lang,result_type=result_type,count=pagecount).items(items):\n",
    "        if 'retweeted_status' in dir(tweet):\n",
    "            text=tweet.retweeted_status.full_text\n",
    "        else:\n",
    "            text=tweet.full_text\n",
    "        msg=[tweet.user.id,tweet.user.name,tweet.user.location,tweet.user.friends_count,tweet.created_at,tweet.retweet_count,tweet.favorite_count,text]\n",
    "        msgs.append(msg)\n",
    "    df=pd.DataFrame(msgs)\n",
    "    df.columns=['user_id','user_name','user_location','user_friends_count','created_time','retweet_count','favourite_count','original_text']\n",
    "    return df\n",
    "\n",
    "def extract_hashtag(text):\n",
    "    hashtag=[]\n",
    "    for i in text:\n",
    "        a=re.findall(r\"#(\\w+)\", i)\n",
    "        hashtag.append([i.capitalize() for i in a])\n",
    "    return hashtag\n",
    "\n",
    "def data_clean(text):\n",
    "    p=re.compile(r'[-,$()#+&*]')\n",
    "    urlclean=re.compile(r'https://[a-zA-Z0-9.?/&=:]*',re.S)\n",
    "    tagclean=re.compile(r'#[a-zA-Z0-9.?/&=:_]*',re.S)\n",
    "    userclean=re.compile(r'@[a-zA-Z0-9.?/&=:_]*',re.S)\n",
    "    cleaned_text=[]\n",
    "\n",
    "    for i in text:\n",
    "        nourl=re.sub(urlclean,\"\",i)\n",
    "        nouser=re.sub(userclean,\"\",nourl)\n",
    "        notag=re.sub(tagclean,\"\",nouser)\n",
    "        clean =notag.replace('\\n',\"\")\n",
    "        cleaned_text.append(clean)\n",
    "    return cleaned_text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_csv() got an unexpected keyword argument 'index_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-fcbc207796ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_crawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhashtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'#vegan'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'extended'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mixed'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpagecount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vegancrawlIN.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf_8_sig'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_hashtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'original_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'original_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: to_csv() got an unexpected keyword argument 'index_col'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = tweets_crawling(hashtag='#vegan',tweet_mode='extended',lang='en',result_type='mixed',pagecount=100,items=100)\n",
    "df.to_csv('vegancraw.csv',header=True,index=True,encoding='utf_8_sig')\n",
    "df['hashtag'] = extract_hashtag(df['original_text'])\n",
    "df['cleaned_text'] = data_clean(df['original_text'])\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>created_time</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>original_text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56814425</td>\n",
       "      <td>espialtoday</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>2314</td>\n",
       "      <td>2020-01-17 17:16:27</td>\n",
       "      <td>1466</td>\n",
       "      <td>0</td>\n",
       "      <td>The feathers needed for bedding, jackets etc. ...</td>\n",
       "      <td>[Govegan, Vegan, Animalrights]</td>\n",
       "      <td>The feathers needed for bedding, jackets etc. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>599677362</td>\n",
       "      <td>Ruby #EndBSL</td>\n",
       "      <td>Deepest Dorset</td>\n",
       "      <td>2517</td>\n",
       "      <td>2020-01-17 17:16:27</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Are you one less person harming animals?‚Å£‚Å†\\n‚Å£‚Å†...</td>\n",
       "      <td>[Vegan]</td>\n",
       "      <td>Are you one less person harming animals?‚Å£‚Å†‚Å£‚Å†Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1013711024</td>\n",
       "      <td>Luci üòà</td>\n",
       "      <td>UK</td>\n",
       "      <td>4965</td>\n",
       "      <td>2020-01-17 17:16:24</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...</td>\n",
       "      <td>[Win, Crueltyfree, Vegan, Paraffinfree, Amazon...</td>\n",
       "      <td>üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>939963727813775361</td>\n",
       "      <td>Mellamigo</td>\n",
       "      <td>Germany</td>\n",
       "      <td>51</td>\n",
       "      <td>2020-01-17 17:16:21</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>How adorable! See this lucky rescued pig üê∑ enj...</td>\n",
       "      <td>[Vegan, Fridaythoughts, Fridayfeeling]</td>\n",
       "      <td>How adorable! See this lucky rescued pig üê∑ enj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2285825144</td>\n",
       "      <td>Mummy Hasson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3793</td>\n",
       "      <td>2020-01-17 17:16:04</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...</td>\n",
       "      <td>[Win, Crueltyfree, Vegan, Paraffinfree, Amazon...</td>\n",
       "      <td>üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             user_id     user_name   user_location  \\\n",
       "0           0            56814425   espialtoday  Houston, Texas   \n",
       "1           1           599677362  Ruby #EndBSL  Deepest Dorset   \n",
       "2           2          1013711024        Luci üòà              UK   \n",
       "3           3  939963727813775361     Mellamigo         Germany   \n",
       "4           4          2285825144  Mummy Hasson  United Kingdom   \n",
       "\n",
       "   user_friends_count         created_time  retweet_count  favourite_count  \\\n",
       "0                2314  2020-01-17 17:16:27           1466                0   \n",
       "1                2517  2020-01-17 17:16:27             49                0   \n",
       "2                4965  2020-01-17 17:16:24            151                0   \n",
       "3                  51  2020-01-17 17:16:21            108                0   \n",
       "4                3793  2020-01-17 17:16:04            151                0   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  The feathers needed for bedding, jackets etc. ...   \n",
       "1  Are you one less person harming animals?‚Å£‚Å†\\n‚Å£‚Å†...   \n",
       "2  üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...   \n",
       "3  How adorable! See this lucky rescued pig üê∑ enj...   \n",
       "4  üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...   \n",
       "\n",
       "                                             hashtag  \\\n",
       "0                     [Govegan, Vegan, Animalrights]   \n",
       "1                                            [Vegan]   \n",
       "2  [Win, Crueltyfree, Vegan, Paraffinfree, Amazon...   \n",
       "3             [Vegan, Fridaythoughts, Fridayfeeling]   \n",
       "4  [Win, Crueltyfree, Vegan, Paraffinfree, Amazon...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  The feathers needed for bedding, jackets etc. ...  \n",
       "1  Are you one less person harming animals?‚Å£‚Å†‚Å£‚Å†Re...  \n",
       "2  üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...  \n",
       "3  How adorable! See this lucky rescued pig üê∑ enj...  \n",
       "4  üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('vegancrawl.csv',index_col=False)\n",
    "df['hashtag'] = extract_hashtag(df['original_text'])\n",
    "df['cleaned_text'] = data_clean(df['original_text'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>created_time</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>original_text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>textblob_SA</th>\n",
       "      <th>textblob_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56814425</td>\n",
       "      <td>espialtoday</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>2314</td>\n",
       "      <td>2020-01-17 17:16:27</td>\n",
       "      <td>1466</td>\n",
       "      <td>0</td>\n",
       "      <td>The feathers needed for bedding, jackets etc. ...</td>\n",
       "      <td>[Govegan, Vegan, Animalrights]</td>\n",
       "      <td>The feathers needed for bedding, jackets etc. ...</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>599677362</td>\n",
       "      <td>Ruby #EndBSL</td>\n",
       "      <td>Deepest Dorset</td>\n",
       "      <td>2517</td>\n",
       "      <td>2020-01-17 17:16:27</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Are you one less person harming animals?‚Å£‚Å†\\n‚Å£‚Å†...</td>\n",
       "      <td>[Vegan]</td>\n",
       "      <td>Are you one less person harming animals?‚Å£‚Å†‚Å£‚Å†Re...</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1013711024</td>\n",
       "      <td>Luci üòà</td>\n",
       "      <td>UK</td>\n",
       "      <td>4965</td>\n",
       "      <td>2020-01-17 17:16:24</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...</td>\n",
       "      <td>[Win, Crueltyfree, Vegan, Paraffinfree, Amazon...</td>\n",
       "      <td>üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>939963727813775361</td>\n",
       "      <td>Mellamigo</td>\n",
       "      <td>Germany</td>\n",
       "      <td>51</td>\n",
       "      <td>2020-01-17 17:16:21</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>How adorable! See this lucky rescued pig üê∑ enj...</td>\n",
       "      <td>[Vegan, Fridaythoughts, Fridayfeeling]</td>\n",
       "      <td>How adorable! See this lucky rescued pig üê∑ enj...</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2285825144</td>\n",
       "      <td>Mummy Hasson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3793</td>\n",
       "      <td>2020-01-17 17:16:04</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...</td>\n",
       "      <td>[Win, Crueltyfree, Vegan, Paraffinfree, Amazon...</td>\n",
       "      <td>üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             user_id     user_name   user_location  \\\n",
       "0           0            56814425   espialtoday  Houston, Texas   \n",
       "1           1           599677362  Ruby #EndBSL  Deepest Dorset   \n",
       "2           2          1013711024        Luci üòà              UK   \n",
       "3           3  939963727813775361     Mellamigo         Germany   \n",
       "4           4          2285825144  Mummy Hasson  United Kingdom   \n",
       "\n",
       "   user_friends_count         created_time  retweet_count  favourite_count  \\\n",
       "0                2314  2020-01-17 17:16:27           1466                0   \n",
       "1                2517  2020-01-17 17:16:27             49                0   \n",
       "2                4965  2020-01-17 17:16:24            151                0   \n",
       "3                  51  2020-01-17 17:16:21            108                0   \n",
       "4                3793  2020-01-17 17:16:04            151                0   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  The feathers needed for bedding, jackets etc. ...   \n",
       "1  Are you one less person harming animals?‚Å£‚Å†\\n‚Å£‚Å†...   \n",
       "2  üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...   \n",
       "3  How adorable! See this lucky rescued pig üê∑ enj...   \n",
       "4  üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...   \n",
       "\n",
       "                                             hashtag  \\\n",
       "0                     [Govegan, Vegan, Animalrights]   \n",
       "1                                            [Vegan]   \n",
       "2  [Win, Crueltyfree, Vegan, Paraffinfree, Amazon...   \n",
       "3             [Vegan, Fridaythoughts, Fridayfeeling]   \n",
       "4  [Win, Crueltyfree, Vegan, Paraffinfree, Amazon...   \n",
       "\n",
       "                                        cleaned_text  textblob_SA  \\\n",
       "0  The feathers needed for bedding, jackets etc. ...     0.117188   \n",
       "1  Are you one less person harming animals?‚Å£‚Å†‚Å£‚Å†Re...    -0.208333   \n",
       "2  üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...     0.123864   \n",
       "3  How adorable! See this lucky rescued pig üê∑ enj...     0.409722   \n",
       "4  üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...     0.123864   \n",
       "\n",
       "  textblob_poly  \n",
       "0      Positive  \n",
       "1      Negative  \n",
       "2      Positive  \n",
       "3      Positive  \n",
       "4      Positive  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_SA=[]\n",
    "textblob_poly=[]\n",
    "for i in df[\"cleaned_text\"]:\n",
    "    analsysis=TextBlob(i)\n",
    "    textblob_SA.append(analsysis.sentiment.polarity)\n",
    "    if analsysis.sentiment.polarity>=0.1:\n",
    "        textblob_poly.append(\"Positive\")\n",
    "    elif analsysis.sentiment.polarity<=-0.1:\n",
    "        textblob_poly.append(\"Negative\")\n",
    "    else:\n",
    "        textblob_poly.append(\"Neutral\")\n",
    "df[\"textblob_SA\"]=textblob_SA\n",
    "df[\"textblob_poly\"]=textblob_poly\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>created_time</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>original_text</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>textblob_SA</th>\n",
       "      <th>textblob_poly</th>\n",
       "      <th>nltk_vsa</th>\n",
       "      <th>nltk_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56814425</td>\n",
       "      <td>espialtoday</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>2314</td>\n",
       "      <td>2020-01-17 17:16:27</td>\n",
       "      <td>1466</td>\n",
       "      <td>0</td>\n",
       "      <td>The feathers needed for bedding, jackets etc. ...</td>\n",
       "      <td>[Govegan, Vegan, Animalrights]</td>\n",
       "      <td>The feathers needed for bedding, jackets etc. ...</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>599677362</td>\n",
       "      <td>Ruby #EndBSL</td>\n",
       "      <td>Deepest Dorset</td>\n",
       "      <td>2517</td>\n",
       "      <td>2020-01-17 17:16:27</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Are you one less person harming animals?‚Å£‚Å†\\n‚Å£‚Å†...</td>\n",
       "      <td>[Vegan]</td>\n",
       "      <td>Are you one less person harming animals?‚Å£‚Å†‚Å£‚Å†Re...</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.5594</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1013711024</td>\n",
       "      <td>Luci üòà</td>\n",
       "      <td>UK</td>\n",
       "      <td>4965</td>\n",
       "      <td>2020-01-17 17:16:24</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...</td>\n",
       "      <td>[Win, Crueltyfree, Vegan, Paraffinfree, Amazon...</td>\n",
       "      <td>üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9066</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>939963727813775361</td>\n",
       "      <td>Mellamigo</td>\n",
       "      <td>Germany</td>\n",
       "      <td>51</td>\n",
       "      <td>2020-01-17 17:16:21</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>How adorable! See this lucky rescued pig üê∑ enj...</td>\n",
       "      <td>[Vegan, Fridaythoughts, Fridayfeeling]</td>\n",
       "      <td>How adorable! See this lucky rescued pig üê∑ enj...</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2285825144</td>\n",
       "      <td>Mummy Hasson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3793</td>\n",
       "      <td>2020-01-17 17:16:04</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...</td>\n",
       "      <td>[Win, Crueltyfree, Vegan, Paraffinfree, Amazon...</td>\n",
       "      <td>üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9066</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             user_id     user_name   user_location  \\\n",
       "0           0            56814425   espialtoday  Houston, Texas   \n",
       "1           1           599677362  Ruby #EndBSL  Deepest Dorset   \n",
       "2           2          1013711024        Luci üòà              UK   \n",
       "3           3  939963727813775361     Mellamigo         Germany   \n",
       "4           4          2285825144  Mummy Hasson  United Kingdom   \n",
       "\n",
       "   user_friends_count         created_time  retweet_count  favourite_count  \\\n",
       "0                2314  2020-01-17 17:16:27           1466                0   \n",
       "1                2517  2020-01-17 17:16:27             49                0   \n",
       "2                4965  2020-01-17 17:16:24            151                0   \n",
       "3                  51  2020-01-17 17:16:21            108                0   \n",
       "4                3793  2020-01-17 17:16:04            151                0   \n",
       "\n",
       "                                       original_text  \\\n",
       "0  The feathers needed for bedding, jackets etc. ...   \n",
       "1  Are you one less person harming animals?‚Å£‚Å†\\n‚Å£‚Å†...   \n",
       "2  üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...   \n",
       "3  How adorable! See this lucky rescued pig üê∑ enj...   \n",
       "4  üåüFollow + RTüåüTo #win INTRODUCING our 100% NATU...   \n",
       "\n",
       "                                             hashtag  \\\n",
       "0                     [Govegan, Vegan, Animalrights]   \n",
       "1                                            [Vegan]   \n",
       "2  [Win, Crueltyfree, Vegan, Paraffinfree, Amazon...   \n",
       "3             [Vegan, Fridaythoughts, Fridayfeeling]   \n",
       "4  [Win, Crueltyfree, Vegan, Paraffinfree, Amazon...   \n",
       "\n",
       "                                        cleaned_text  textblob_SA  \\\n",
       "0  The feathers needed for bedding, jackets etc. ...     0.117188   \n",
       "1  Are you one less person harming animals?‚Å£‚Å†‚Å£‚Å†Re...    -0.208333   \n",
       "2  üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...     0.123864   \n",
       "3  How adorable! See this lucky rescued pig üê∑ enj...     0.409722   \n",
       "4  üåüFollow + RTüåüTo  INTRODUCING our 100% NATURAL ...     0.123864   \n",
       "\n",
       "  textblob_poly  nltk_vsa nltk_poly  \n",
       "0      Positive    0.2579  Positive  \n",
       "1      Negative   -0.5594  Negative  \n",
       "2      Positive    0.9066  Positive  \n",
       "3      Positive    0.9870  Positive  \n",
       "4      Positive    0.9066  Positive  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_vsa=[]\n",
    "nltk_poly=[]\n",
    "sid=SentimentIntensityAnalyzer()\n",
    "for i in df[\"cleaned_text\"]:\n",
    "    nltk_vsa.append(sid.polarity_scores(i)['compound'])\n",
    "    if sid.polarity_scores(i)['compound']>=0.1:\n",
    "        nltk_poly.append(\"Positive\")\n",
    "    elif sid.polarity_scores(i)['compound']<=-0.1:\n",
    "        nltk_poly.append(\"Negative\")\n",
    "    else:\n",
    "        nltk_poly.append(\"Neutral\")\n",
    "        \n",
    "df[\"nltk_vsa\"]=nltk_vsa\n",
    "df[\"nltk_poly\"]=nltk_poly\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
